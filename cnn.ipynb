{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import node\n",
    "import node.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Classifier(node.Network):\n",
    "    \n",
    "    def __init__(self, num_in_ch):\n",
    "        self.layers = [node.Conv2D(num_in_ch, 16, 3),\n",
    "                       node.MaxPool2D(3, 2),\n",
    "                       node.Conv2D(16, 32, 3),\n",
    "                       node.MaxPool2D(3, 2),\n",
    "                       node.Linear(512, 256),\n",
    "                       node.Linear(256, 10)]\n",
    "        \n",
    "    def __call__(self, input):\n",
    "        hidden = input\n",
    "        hidden = self.layers[1](self.layers[0](hidden)).relu()\n",
    "        hidden = self.layers[3](self.layers[2](hidden)).relu()\n",
    "        hidden = hidden.reshape(input.value.shape[0], -1)\n",
    "        hidden = self.layers[4](hidden).relu()\n",
    "        hidden = self.layers[5](hidden)      \n",
    "        return hidden\n",
    "    \n",
    "classifier = Classifier(1).gpu()\n",
    "optimizer = node.Adam(classifier.get_parameters(), 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = [node.MNIST(training=True), node.MNIST(training=False)]\n",
    "data_loaders = [node.DataLoader(datasets[0], batch_size=100), node.DataLoader(datasets[1], batch_size=100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input, target):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #　パラメーターを更新する\n",
    "    output = classifier(input/255).softmax_with_cross_entropy(target)\n",
    "    output.backward()\n",
    "    optimizer()\n",
    "    \n",
    "    return output.cpu().value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure(prediction, target):\n",
    "    # 出力とラベルを受け取り、何個正解したかの数を返す。\n",
    "    prediction = cp.argmax(prediction.value, axis=1)\n",
    "    target = cp.argmax(target.value, axis=1)\n",
    "    \n",
    "    return cp.asnumpy(cp.sum(cp.where(prediction == target, 1, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(input, target):\n",
    "    with node.zero_grad():\n",
    "        prediction = classifier(input/255)\n",
    "        output = prediction.softmax_with_cross_entropy(target)\n",
    "        \n",
    "    loss = output.cpu().value\n",
    "    accuracy = measure(prediction, target)\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0, training loss 0.54, test loss 0.21, accuracy 0.96\n",
      "epoch  1, training loss 0.17, test loss 0.14, accuracy 0.98\n",
      "epoch  2, training loss 0.13, test loss 0.19, accuracy 0.97\n",
      "epoch  3, training loss 0.11, test loss 0.11, accuracy 0.98\n",
      "epoch  4, training loss 0.08, test loss 0.10, accuracy 0.98\n",
      "epoch  5, training loss 0.07, test loss 0.10, accuracy 0.99\n",
      "epoch  6, training loss 0.06, test loss 0.10, accuracy 0.98\n",
      "epoch  7, training loss 0.05, test loss 0.09, accuracy 0.99\n",
      "epoch  8, training loss 0.04, test loss 0.09, accuracy 0.99\n",
      "epoch  9, training loss 0.04, test loss 0.11, accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    \n",
    "    # Train Loss, Test Loss, Accuracy\n",
    "    metrics = [0, 0, 0]\n",
    "\n",
    "    for input, target in data_loaders[0]:\n",
    "        metrics[0] += train(input.gpu(), target.gpu())\n",
    "        \n",
    "    for input, target in data_loaders[1]:\n",
    "        loss, accuracy = evaluate(input.gpu(), target.gpu())\n",
    "        metrics[1] += loss \n",
    "        metrics[2] += accuracy\n",
    "        \n",
    "    metrics[0] /= len(data_loaders[0])\n",
    "    metrics[1] /= len(data_loaders[1])\n",
    "    metrics[2] /= 100 * len(data_loaders[1])\n",
    "    \n",
    "    print(\"epoch {0:2}, training loss {1:.2f}, test loss {2:.2f}, accuracy {3:.2f}\".format(epoch, *metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
