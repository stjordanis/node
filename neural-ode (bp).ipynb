{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal Implementation of Neural ODE\n",
    "\n",
    "* Reference  \n",
    "https://arxiv.org/abs/1806.07366  \n",
    "https://github.com/rtqichen/torchdiffeq (PyTorch Imlementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Works on GPU\n"
     ]
    }
   ],
   "source": [
    "import node \n",
    "import numpy as np\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EularMethod(object):\n",
    "    \n",
    "    def __init__(self, fn, input):\n",
    "        self.fn = fn\n",
    "        self.value = input\n",
    "    \n",
    "    def step(self, time, diff, input):\n",
    "        return self.fn(time, input) * diff\n",
    "    \n",
    "    def integrate(self, seq):\n",
    "        outputs = []        \n",
    "        for t0, t1 in zip(seq[:-1], seq[1:]):\n",
    "            dout = self.step(t0, t1 - t0, self.value)\n",
    "            self.value = self.value + dout\n",
    "            outputs.append(self.value)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve(fn, input, seq):\n",
    "    solver = EularMethod(fn, input)\n",
    "    outputs = solver.integrate(seq)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction\n",
    "\n",
    "I followed the model structure used on https://github.com/rtqichen/torchdiffeq.  \n",
    "\n",
    "Model consists of   　　\n",
    "```sequence\n",
    "DownSampler ===> NeuralODEBlock x n ===> Classifier\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_ch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DownSampler(node.Network):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.layers = [node.Convolution2D(1, num_ch, 3, 1),\n",
    "                       node.BatchNormalization(num_ch),\n",
    "                       node.Convolution2D(num_ch, num_ch, 4, 2, 1),\n",
    "                       node.BatchNormalization(num_ch),\n",
    "                       node.Convolution2D(num_ch, num_ch, 4, 2, 1)]\n",
    "        \n",
    "    def __call__(self, input):\n",
    "        hidden = input\n",
    "        \n",
    "        # Block 1\n",
    "        # Output: num_ch x 26 x 26\n",
    "        hidden = self.layers[0](hidden)\n",
    "        hidden = self.layers[1](hidden)\n",
    "        hidden = hidden.relu()\n",
    "        \n",
    "        # Block 2 \n",
    "        # Output: num_ch x 13 x 13\n",
    "        hidden = self.layers[2](hidden)\n",
    "        hidden = self.layers[3](hidden)\n",
    "        hidden = hidden.relu()\n",
    "        \n",
    "        # Block 3\n",
    "        # Output: num_ch x 6 x 6\n",
    "        hidden = self.layers[4](hidden)\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConcatenatedConvolution2D(node.Network):\n",
    "    \n",
    "    def __init__(self, num_in_ch, num_out_ch, *args):\n",
    "        self.layers = [node.Convolution2D(num_in_ch+1, num_out_ch, *args)]\n",
    "        \n",
    "    def __call__(self, time, input):\n",
    "        hidden = node.Node(cp.ones_like(input.value[:, :1, :, :])) * time\n",
    "        hidden = node.concatenate([hidden, input], 1)\n",
    "        hidden = self.layers[0](hidden)\n",
    "        return hidden\n",
    "\n",
    "class NeuralODEBlock(node.Network):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.layers = [node.BatchNormalization(num_ch),\n",
    "                       ConcatenatedConvolution2D(num_ch, num_ch, 3, 1, 1),\n",
    "                       node.BatchNormalization(num_ch),\n",
    "                       ConcatenatedConvolution2D(num_ch, num_ch, 3, 1, 1),\n",
    "                       node.BatchNormalization(num_ch)]\n",
    "        \n",
    "        # Adjust here to change resolution\n",
    "        self.start2stop = cp.arange(0, 2, 1)\n",
    "        \n",
    "    def fn(self, time, input):\n",
    "        hidden = input\n",
    "        \n",
    "        # Block 1 \n",
    "        hidden = self.layers[0](hidden)\n",
    "        hidden = hidden.relu()\n",
    "        \n",
    "        # Block 2\n",
    "        hidden = self.layers[1](time, hidden)\n",
    "        hidden = self.layers[2](hidden)\n",
    "        \n",
    "        # Block 3\n",
    "        hidden = self.layers[3](time, hidden)\n",
    "        hidden = self.layers[4](hidden)\n",
    "        \n",
    "        return hidden\n",
    "    \n",
    "    def __call__(self, input):\n",
    "        output = solve(self.fn, input, self.start2stop)\n",
    "        return output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Classifier(node.Network):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.layers = [node.BatchNormalization(num_ch),\n",
    "                       node.Linear(1152, 10)]\n",
    "        \n",
    "    def __call__(self, input):\n",
    "        hidden = input\n",
    "        \n",
    "        # Block 1 \n",
    "        # Output: num_ch x 6 x 6\n",
    "        hidden = self.layers[0](hidden)\n",
    "        hidden = hidden.relu()\n",
    "        \n",
    "        # Fully-connected Layer\n",
    "        hidden = hidden.reshape(input.value.shape[0], -1)\n",
    "        hidden = self.layers[1](hidden)\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter size: 64138\n"
     ]
    }
   ],
   "source": [
    "class MainClassifier(node.Network):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.layers = [DownSampler(),\n",
    "                       NeuralODEBlock(),\n",
    "                       Classifier()]\n",
    "        \n",
    "    def __call__(self, input):\n",
    "        hidden = input\n",
    "        hidden = self.layers[0](hidden)\n",
    "        hidden = self.layers[1](hidden)\n",
    "        hidden = self.layers[2](hidden)\n",
    "        return hidden\n",
    "    \n",
    "classifier = MainClassifier()\n",
    "optimizer = node.Adam(classifier.get_parameters(), 0.001)\n",
    "print(\"parameter size: {}\".format(classifier.get_num_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_batch_size = 100\n",
    "\n",
    "datasets = [node.MNIST(train=True), \n",
    "            node.MNIST(train=False)]\n",
    "\n",
    "dataloaders = [node.DataLoader(datasets[0], mini_batch_size),\n",
    "               node.DataLoader(datasets[1], mini_batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input, target):\n",
    "    prediction = classifier(input / 255)\n",
    "    output = prediction.softmax_with_binary_cross_entropy(target)\n",
    "    \n",
    "    optimizer.clear()\n",
    "    output.backward()\n",
    "    optimizer.update()\n",
    "    \n",
    "    return output.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(input, target):\n",
    "    \n",
    "    def measure(prediction, target):\n",
    "        prediction = np.argmax(prediction, axis=1)\n",
    "        target = np.argmax(target, axis=1)\n",
    "        return np.sum(np.where(prediction == target, 1, 0))\n",
    "    \n",
    "    with node.zero_grad():\n",
    "        prediction = classifier(input / 255)\n",
    "        output = prediction.softmax_with_binary_cross_entropy(target)\n",
    "        \n",
    "    acc = measure(prediction.numpy(), target.numpy())\n",
    "        \n",
    "    return output.numpy(), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0, train 5.3297, test 2.0402, acc 0.8261\n",
      "epoch  1, train 1.5144, test 1.1446, acc 0.8892\n",
      "epoch  2, train 0.9191, test 0.7925, acc 0.9142\n",
      "epoch  3, train 0.6488, test 0.5943, acc 0.9271\n",
      "epoch  4, train 0.4904, test 0.4892, acc 0.9349\n",
      "epoch  5, train 0.3875, test 0.4056, acc 0.9432\n",
      "epoch  6, train 0.3149, test 0.3376, acc 0.9501\n",
      "epoch  7, train 0.2653, test 0.2814, acc 0.9603\n",
      "epoch  8, train 0.2243, test 0.2551, acc 0.9616\n",
      "epoch  9, train 0.1945, test 0.2360, acc 0.9629\n",
      "epoch 10, train 0.1705, test 0.2073, acc 0.9687\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(11):\n",
    "    # Train Loss, Test Loss, Accuracy\n",
    "    metrics = [0, 0, 0]\n",
    "\n",
    "    for input, target in dataloaders[0]:\n",
    "        metrics[0] += train(input, target)\n",
    "        \n",
    "    for input, target in dataloaders[1]:\n",
    "        loss, acc = evaluate(input, target)\n",
    "        metrics[1] += loss\n",
    "        metrics[2] += acc\n",
    "            \n",
    "    metrics[0] /= len(dataloaders[0])\n",
    "    metrics[1] /= len(dataloaders[1])\n",
    "    metrics[2] /= 100 * len(dataloaders[1])\n",
    "    if epoch % 1 == 0:\n",
    "        print(\"epoch {0:2}, train {1:.4f}, test {2:.4f}, acc {3:.4f}\".format(epoch, *metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
