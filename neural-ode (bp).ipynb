{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Works on CPU\n"
     ]
    }
   ],
   "source": [
    "import node \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EularMethod(object):\n",
    "    \n",
    "    def __init__(self, fn, input):\n",
    "        self.fn = fn\n",
    "        self.value = input\n",
    "    \n",
    "    def step(self, time, diff, input):\n",
    "        return diff * self.fn(time, input)\n",
    "    \n",
    "    def integrate(self, seq):\n",
    "        outputs = []        \n",
    "        for t0, t1 in zip(seq[:-1], seq[1:]):\n",
    "            dout = self.step(t0, t1 - t0, self.value)\n",
    "            self.value = dout + self.value\n",
    "            outputs.append(self.value)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(fn, input, seq):\n",
    "    solver = EularMethod(fn, input)\n",
    "    outputs = solver.integrate(seq)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction\n",
    "\n",
    "Model consists of   　　\n",
    "```sequence\n",
    "DownSampler ===> NeuralODEBlock x n ===> Classifier\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSampler(node.Network):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.layers = [node.Convolution2D(1, 64, 3, 1),\n",
    "                       node.BatchNormalization(64),\n",
    "                       node.Convolution2D(64, 64, 4, 2, 1),\n",
    "                       node.BatchNormalization(64),\n",
    "                       node.Convolution2D(64, 64, 4, 2, 1)]\n",
    "        \n",
    "    def __call__(self, input):\n",
    "        hidden = input\n",
    "        \n",
    "        # Block 1\n",
    "        # Output: 64 x 26 x 26\n",
    "        hidden = self.layers[0](hidden)\n",
    "        hidden = self.layers[1](hidden)\n",
    "        hidden = hidden.relu()\n",
    "        \n",
    "        # Block 2 \n",
    "        # Output: 64 x 13 x 13\n",
    "        hidden = self.layers[2](hidden)\n",
    "        hidden = self.layers[3](hidden)\n",
    "        hidden = hidden.relu()\n",
    "        \n",
    "        # Block 3\n",
    "        # Output: 64 x 6 x 6\n",
    "        hidden = self.layers[4](hidden)\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatenatedConvolution2D(node.Network):\n",
    "    \n",
    "    def __init__(self, num_in_ch, num_out_ch, *args):\n",
    "        self.layers = [node.Convolution2D(num_in_ch+1, num_out_ch, *args)]\n",
    "        \n",
    "    def __call__(self, time, input):\n",
    "        hidden = node.Node(np.ones_like(input.value[:, :1, :, :])) * time\n",
    "        hidden = node.concatenate([hidden, input], 1)\n",
    "        hidden = self.layers[0](hidden)\n",
    "        return hidden\n",
    "\n",
    "class NeuralODEBlock(node.Network):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.layers = [node.BatchNormalization(64),\n",
    "                       ConcatenatedConvolution2D(64, 64, 3, 1, 1),\n",
    "                       node.BatchNormalization(64),\n",
    "                       ConcatenatedConvolution2D(64, 64, 3, 1, 1),\n",
    "                       node.BatchNormalization(64)]\n",
    "        \n",
    "        self.start2stop = np.arange(0, 2, 1)\n",
    "        \n",
    "    def fn(self, time, input):\n",
    "        hidden = input\n",
    "        \n",
    "        # Block 1 \n",
    "        hidden = self.layers[0](hidden)\n",
    "        hidden = hidden.relu()\n",
    "        \n",
    "        # Block 2\n",
    "        hidden = self.layers[1](time, hidden)\n",
    "        hidden = self.layers[2](hidden)\n",
    "        \n",
    "        # Block 3\n",
    "        hidden = self.layers[3](time, hidden)\n",
    "        hidden = self.layers[4](hidden)\n",
    "        \n",
    "        return hidden\n",
    "    \n",
    "    def __call__(self, input):\n",
    "        output = solve(self.fn, input, self.start2stop)\n",
    "        return output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(node.Network):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.layers = [node.BatchNormalization(64),\n",
    "                       node.Linear(2304, 10)]\n",
    "        \n",
    "    def __call__(self, input):\n",
    "        hidden = input\n",
    "        \n",
    "        # Block 1 \n",
    "        # Output: 64 x 6 x 6\n",
    "        hidden = self.layers[0](hidden)\n",
    "        hidden = hidden.relu()\n",
    "        \n",
    "        # Fully-connected Layer\n",
    "        hidden = hidden.reshape(input.value.shape[0], -1)\n",
    "        hidden = self.layers[1](hidden)\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter size: 230666\n"
     ]
    }
   ],
   "source": [
    "class MainClassifier(node.Network):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.layers = [DownSampler(),\n",
    "                       NeuralODEBlock(),\n",
    "                       Classifier()]\n",
    "        \n",
    "    def __call__(self, input):\n",
    "        hidden = input\n",
    "        hidden = self.layers[0](hidden)\n",
    "        hidden = self.layers[1](hidden)\n",
    "        hidden = self.layers[2](hidden)\n",
    "        return hidden\n",
    "    \n",
    "classifier = MainClassifier()\n",
    "optimizer = node.Adam(classifier.get_parameters(), 0.001)\n",
    "\n",
    "# Slightly larger than 0.22M because I did not use adaptive average pooling layer\n",
    "# Rather, I used fully-connected layer\n",
    "print(\"parameter size: {}\".format(classifier.get_num_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_size = 100\n",
    "\n",
    "datasets = [node.MNIST(train=True), \n",
    "            node.MNIST(train=False)]\n",
    "\n",
    "dataloaders = [node.DataLoader(datasets[0], mini_batch_size),\n",
    "               node.DataLoader(datasets[1], mini_batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input, target):\n",
    "    prediction = classifier(input / 255)\n",
    "    output = prediction.softmax_with_binary_cross_entropy(target)\n",
    "    \n",
    "    optimizer.clear()\n",
    "    output.backward()\n",
    "    optimizer.update()\n",
    "    \n",
    "    return output.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25def82cff5a42e7824675372ed1a66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(11):\n",
    "    # Train Loss, Test Loss, Accuracy\n",
    "    metrics = [0, 0, 0]\n",
    "\n",
    "    for input, target in tqdm(dataloaders[0]):\n",
    "        metrics[0] += train(input, target)\n",
    "        \n",
    "    if epoch % 5 == 0:\n",
    "        print(\"epoch {0:2}, train {1:.4f}, test {2:.4f}, acc {3:.4f}\".format(epoch, *metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [node.Node(np.random.randn(3, 1, 3)) for _ in range(10)]\n",
    "seq = node.concatenate(seq, 1)\n",
    "print(seq.value.shape)\n",
    "seq.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
