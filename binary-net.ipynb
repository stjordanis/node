{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Works on GPU\n"
     ]
    }
   ],
   "source": [
    "import node\n",
    "import numpy as np\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node.node import _single_oprand_op\n",
    "\n",
    "class Activate(node.Op):\n",
    "\n",
    "    def __init__(self, x, *args):\n",
    "        super(Activate, self).__init__()\n",
    "        self.register(x)\n",
    "        self.output = self.forward()\n",
    "        \n",
    "    def forward(self):\n",
    "        x = self.cache[0]\n",
    "        return cp.sign(x.value)\n",
    "\n",
    "    def backward(self, error):\n",
    "        x = self.cache[0]\n",
    "        x.accumulate(error * 1 * (cp.abs(self.output) <= 1))\n",
    "    \n",
    "@_single_oprand_op\n",
    "def activate(self):\n",
    "    return Activate(self)\n",
    "\n",
    "setattr(node.Node, \"activate\", activate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BinaryLinear(node.Layer):\n",
    "    \n",
    "    def __init__(self, num_in_units, num_h_units):\n",
    "        super(BinaryLinear, self).__init__()\n",
    "        \n",
    "        self.parameters = {\n",
    "            \"W\": node.Node(cp.random.randn(num_in_units, num_h_units), name=\"W\")\n",
    "        }\n",
    "        \n",
    "    def __call__(self, input):\n",
    "        return input.dot(self.parameters[\"W\"].activate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has 1865748 parameters\n"
     ]
    }
   ],
   "source": [
    "class BinaryNet(node.Network):\n",
    "    \n",
    "    def __init__(self, num_in_units, num_h_units, num_out_units):\n",
    "        self.layers = [BinaryLinear(num_in_units, num_h_units),\n",
    "                       node.BatchNormalization(num_h_units),\n",
    "                       BinaryLinear(num_h_units, num_h_units),\n",
    "                       node.BatchNormalization(num_h_units),\n",
    "                       BinaryLinear(num_h_units, num_out_units),\n",
    "                       node.BatchNormalization(num_out_units)]\n",
    "        \n",
    "    def __call__(self, input):\n",
    "        hidden = input\n",
    "        hidden = self.layers[1](self.layers[0](hidden)).activate()\n",
    "        hidden = self.layers[3](self.layers[2](hidden)).activate()\n",
    "        hidden = self.layers[5](self.layers[4](hidden))\n",
    "        return hidden\n",
    "    \n",
    "classifier = BinaryNet(784, 1024, 10)\n",
    "optimizer = node.Adam(classifier.get_parameters(), eta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = node.MNIST(train=True, flatten=True)\n",
    "train_dataloader = node.DataLoader(train_dataset, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = node.MNIST(train=False, flatten=True)\n",
    "test_dataloader = node.DataLoader(test_dataset, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(input, target):\n",
    "    output = classifier(input / 255).softmax_with_binary_cross_entropy(target)\n",
    "    optimizer.clear()\n",
    "    output.backward()\n",
    "    optimizer.update()\n",
    "    return output.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure(prediction, target):\n",
    "    prediction = np.argmax(prediction, axis=1)\n",
    "    target = np.argmax(target, axis=1)\n",
    "    return np.sum(np.where(prediction == target, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(input, target):\n",
    "    with node.zero_grad():\n",
    "        prediction = classifier(input/255)\n",
    "        output = prediction.softmax_with_binary_cross_entropy(target)\n",
    "        \n",
    "    loss = output.numpy()\n",
    "    accuracy = measure(prediction.numpy(), target.numpy())\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0, training loss 1.7738, test loss 1.1775, accuracy 0.8756\n",
      "epoch   5, training loss 0.5439, test loss 0.4837, accuracy 0.9222\n",
      "epoch  10, training loss 0.4234, test loss 0.4054, accuracy 0.9301\n",
      "epoch  15, training loss 0.3820, test loss 0.3828, accuracy 0.9324\n",
      "epoch  20, training loss 0.3537, test loss 0.3679, accuracy 0.9339\n",
      "epoch  25, training loss 0.3355, test loss 0.3604, accuracy 0.9345\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(26):\n",
    "    \n",
    "    # Train Loss, Test Loss, Accuracy\n",
    "    metrics = [0, 0, 0]\n",
    "    \n",
    "    classifier.train()\n",
    "    for input, target in train_dataloader:\n",
    "        metrics[0] += train(input, target)\n",
    "\n",
    "    classifier.test()\n",
    "    for input, target in test_dataloader:\n",
    "        loss, accuracy = evaluate(input, target)\n",
    "        metrics[1] += loss \n",
    "        metrics[2] += accuracy\n",
    "        \n",
    "    metrics[0] /= len(train_dataloader)\n",
    "    metrics[1] /= len(test_dataloader)\n",
    "    metrics[2] /= 100 * len(test_dataloader)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(\"epoch {0:3}, training loss {1:.4f}, test loss {2:.4f}, accuracy {3:.4f}\".format(epoch, *metrics))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
